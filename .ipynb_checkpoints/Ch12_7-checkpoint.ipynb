{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad01ccb-7c18-4720-9ca9-1eb9d37328d8",
   "metadata": {},
   "source": [
    "## Chapter 12: Discriminant Analysis and Other Linear Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6028bd74-a9cb-4f73-8812-cc035d747bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rpy2 import robjects\n",
    "from rpy2.robjects.packages import importr, data\n",
    "import os\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.gray()\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f06a69f-801b-4b6b-b1d9-e2b6f8ae85ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = importr('base')\n",
    "set_seed = robjects.r(\"set.seed\")\n",
    "APM = importr('AppliedPredictiveModeling')\n",
    "APMdatafolder = os.path.expanduser(\"~/Documents/dataset/AppliedPredictiveModeling/data\")\n",
    "print(os.path.isdir(APMdatafolder))\n",
    "unimelbdatafolder = os.path.expanduser(\"~/Documents/dataset/unimelb\")\n",
    "os.path.isdir(unimelbdatafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c22b42-8e34-4612-9075-c7dfadf17808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindata_filename='unimelb_training.csv'\n",
    "trainfile_path = os.path.join(unimelbdatafolder, traindata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20263fec-8d08-4afd-9880-11936479e4bc",
   "metadata": {},
   "source": [
    "### 1. Data clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa53e2-04f3-4a58-bd8e-1574e30da045",
   "metadata": {},
   "source": [
    "#### A few utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ab47b09-97aa-42e7-9b5f-ec87b8c0f6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanRawData(raw0):\n",
    "    raw = raw0.copy()\n",
    "    raw['Sponsor.Code'] = raw['Sponsor.Code'].fillna('Unk')\n",
    "    raw['Sponsor.Code'] = 'Sponsor'+raw['Sponsor.Code']\n",
    "\n",
    "    raw['Grant.Category.Code'] = raw['Grant.Category.Code'].fillna('Unk')\n",
    "    raw['Grant.Category.Code'] = 'GrantCat'+raw['Grant.Category.Code']\n",
    "\n",
    "    raw['Contract.Value.Band...see.note.A'] = raw['Contract.Value.Band...see.note.A'].fillna('Unk')\n",
    "    raw['Contract.Value.Band...see.note.A'] = 'ContractValueBand'+raw['Contract.Value.Band...see.note.A']\n",
    "\n",
    "    raw['Role.1'] = raw['Role.1'].fillna('Unk')\n",
    "    return raw\n",
    "    \n",
    "def getVerticalData(raw, namesPre):\n",
    "    tmp = []\n",
    "    for i in range(1,16):\n",
    "        tmpData = pd.DataFrame()\n",
    "        tmpData['Grant.Application.ID'] = raw['Grant.Application.ID']\n",
    "        for x in namesPre:\n",
    "            if x+'.'+str(i) in raw.columns:\n",
    "                tmpData[x] = raw[x+'.'+str(i)]\n",
    "        tmp.append(tmpData)\n",
    "    vertical = pd.concat(tmp)\n",
    "    vertical = vertical[vertical['Role'].notnull()]\n",
    "    return vertical\n",
    "\n",
    "def cleanVerticalData(v0):\n",
    "    v = v0.copy()\n",
    "    v.loc[v['Country.of.Birth'].notnull(),'Country.of.Birth'] = \\\n",
    "        v[v['Country.of.Birth'].notnull()]['Country.of.Birth'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "    \n",
    "    v['Home.Language'] = v['Home.Language'].apply(lambda x: 'OtherLang' if x=='Other' else x)\n",
    "    v['Dept.No.'] = v['Dept.No.'].apply(lambda x: 'Dept'+str(int(x)) if pd.notna(x) else 'DeptNA')\n",
    "    v['Faculty.No.'] = v['Faculty.No.'].apply(lambda x: 'Faculty'+str(int(x)) if pd.notna(x) else 'FacultyNA')\n",
    "    \n",
    "    v['RFCD.Code'] = v['RFCD.Code'].apply(lambda x: 'RFCD'+str(int(x)) if pd.notna(x) else 'RFCDNA')\n",
    "    v['RFCD.Code'] = v['RFCD.Code'].apply(lambda x: 'RFCDNA' if x in ['RFCD0','RFCD999999'] else x)\n",
    "    v.loc[v['RFCD.Code'].isin(['RFCDNA']),'RFCD.Percentage'] = None\n",
    "    \n",
    "    v['SEO.Code'] = v['SEO.Code'].apply(lambda x: 'SEO'+str(int(x)) if pd.notna(x) else 'SEONA')\n",
    "    v['SEO.Code'] = v['SEO.Code'].apply(lambda x: 'SEONA' if x in ['SEO0','SEO999999'] else x)\n",
    "    v.loc[v['SEO.Code'].isin(['SEONA']),'SEO.Percentage'] = None\n",
    "    \n",
    "    colName = 'No..of.Years.in.Uni.at.Time.of.Grant'\n",
    "    v[colName] = v[colName].map({'>=0 to 5':'Duration0to5',\n",
    "                                 '>5 to 10':'Duration5to10',\n",
    "                                 '>10 to 15':'Duration10to15',\n",
    "                                 'more than 15':'DurationGT15',\n",
    "                                 'Less than 0':'DurationLT0'},\n",
    "                           na_action='ignore')\n",
    "    v[colName] = v[colName].fillna('DurationUnk')\n",
    "    \n",
    "    return v\n",
    "\n",
    "def noZV(w): \n",
    "    dropColumns = []\n",
    "    for c in w.columns:\n",
    "        if len(w[c].drop_duplicates())==1:\n",
    "            dropColumns.append(c)\n",
    "    return w.drop(columns = dropColumns)\n",
    "    \n",
    "def getSummaryData(v):\n",
    "    people, totalPub, investPub, investDuration, investFaculty, investDept, investGrants, \\\n",
    "        investPhD, investLang, investCountry, investDOB, investCount, grantData, SEOcount, RFCDcount \\\n",
    "        = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(),\\\n",
    "        pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(),\\\n",
    "        pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    allID = v[['Grant.Application.ID']].drop_duplicates().sort_values('Grant.Application.ID')\n",
    "    \n",
    "    shortNames = {\"EXT_CHIEF_INVESTIGATOR\":\"ECI\", \"STUD_CHIEF_INVESTIGATOR\":\"SCI\", \"CHIEF_INVESTIGATOR\":\"CI\",\\\n",
    "                 \"DELEGATED_RESEARCHER\":\"DR\", \"EXTERNAL_ADVISOR\":\"EA\", \"HONVISIT\":\"HV\",\\\n",
    "                 \"PRINCIPAL_SUPERVISOR\":\"PS\", \"STUDRES\":\"SR\", \"Unk\":\"UNK\", \"\":\"\"}\n",
    "    \n",
    "    # calculate the number of people per Grant application\n",
    "    w = v.groupby('Grant.Application.ID').agg(numPeople = ('Grant.Application.ID','count')).reset_index()\n",
    "    people = noZV(allID.merge(w, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # calculate the number of people per role\n",
    "    pt = v[['Grant.Application.ID','Role']].groupby(['Grant.Application.ID', 'Role']).\\\n",
    "        agg(num = ('Role','count')).reset_index().\\\n",
    "        pivot(index = 'Grant.Application.ID',columns = 'Role').reset_index()\n",
    "    newcolname = [x[0]+shortNames[x[1]] for x in pt.columns]\n",
    "    pt.columns = newcolname\n",
    "    pt = pt.fillna(0)\n",
    "    investCount = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # for each role, calculate the frequency of people in each age group\n",
    "    x = v[['Grant.Application.ID','Role','Year.of.Birth']].\\\n",
    "        groupby(['Grant.Application.ID','Role','Year.of.Birth']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['Year.of.Birth','Role'])\n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+\".\"+x['Year.of.Birth'].astype(int).astype(str)\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    investDOB = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # for each role, calculate the frequency of people from each country\n",
    "    x = v[['Grant.Application.ID','Role','Country.of.Birth']].\\\n",
    "        groupby(['Grant.Application.ID','Role','Country.of.Birth']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['Country.of.Birth','Role'])\n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+\".\"+x['Country.of.Birth']\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    investCountry = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # for each role, calculate the frenquency of people for each language\n",
    "    x = v[['Grant.Application.ID','Role','Home.Language']].\\\n",
    "        groupby(['Grant.Application.ID','Role','Home.Language']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['Home.Language','Role'])\n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+\".\"+x['Home.Language']\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    investLang = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left').fillna(0))\n",
    "    \n",
    "    # for each role, determine who has a Ph.D\n",
    "    x = v[['Grant.Application.ID','Role','With.PHD']].\\\n",
    "        groupby(['Grant.Application.ID','Role','With.PHD']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['With.PHD','Role'])    \n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+'.PhD'\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    for x in ['EA.PhD','SCI.PhD','UNK.PhD']:\n",
    "        pt[x]=0\n",
    "    investPhD = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # for each role, calculate the number of successful and unsuccessful grants\n",
    "    x = v[['Grant.Application.ID','Role','Number.of.Successful.Grant']].\\\n",
    "        groupby(['Grant.Application.ID','Role']).\\\n",
    "        agg(num = ('Number.of.Successful.Grant','sum')).reset_index()\n",
    "    x = x.sort_values(['Role'])\n",
    "    x['roleC'] = 'Success.'+x['Role'].map(shortNames,na_action = 'ignore')\n",
    "    \n",
    "    y = v[['Grant.Application.ID','Role','Number.of.Unsuccessful.Grant']].\\\n",
    "        groupby(['Grant.Application.ID','Role']).\\\n",
    "        agg(num = ('Number.of.Unsuccessful.Grant','sum')).reset_index()\n",
    "    y = y.sort_values(['Role'])\n",
    "    y['roleC'] = 'Unsuccess.'+y['Role'].map(shortNames,na_action = 'ignore')\n",
    "    pt = pd.concat([x,y]).pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    investGrants = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # Create variables for each role/department combination\n",
    "    x = v[['Grant.Application.ID','Role','Dept.No.']].\\\n",
    "        groupby(['Grant.Application.ID','Role','Dept.No.']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['Dept.No.','Role'])\n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+\".\"+x['Dept.No.']\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]\n",
    "    pt = pt[[x for x in pt.columns if 'DeptNA' not in x]]\n",
    "    investDept = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # Create variables for each role/faculty\n",
    "    x = v[['Grant.Application.ID','Role','Faculty.No.']].\\\n",
    "        groupby(['Grant.Application.ID','Role','Faculty.No.']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    x = x.sort_values(['Faculty.No.','Role'])\n",
    "    x['roleC'] = x['Role'].map(shortNames,na_action = 'ignore')+\".\"+x['Faculty.No.']\n",
    "    pt = x.pivot(index = 'Grant.Application.ID',columns = 'roleC',values = 'num').fillna(0).reset_index()\n",
    "    pt.columns.names = [None]    \n",
    "    pt = pt[[x for x in pt.columns if 'NA' not in x]]\n",
    "    investFaculty = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # Create dummy variables for each tenure length\n",
    "    x = v[['Grant.Application.ID','No..of.Years.in.Uni.at.Time.of.Grant']].\\\n",
    "        groupby(['Grant.Application.ID','No..of.Years.in.Uni.at.Time.of.Grant']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    pt = x.pivot(index = 'Grant.Application.ID', columns = 'No..of.Years.in.Uni.at.Time.of.Grant', values = 'num').fillna(0)\n",
    "    pt.columns.names = [None]\n",
    "    investDuration = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # Create variables for the number of publications per journal type. \n",
    "    # Note that we also compute the total number, \n",
    "    # which should be removed for models that cannot deal with such a linear dependency\n",
    "    x = v[['Grant.Application.ID','A.','A','B','C']].\\\n",
    "    groupby('Grant.Application.ID').\\\n",
    "    agg(AstarTotal = ('A.','sum'), ATotal=('A','sum'),BTotal = ('B', 'sum'), CTotal = ('C','sum')).reset_index().fillna(0)\n",
    "    x['allPub'] = x['AstarTotal']+x['ATotal']+x['BTotal']+x['CTotal']\n",
    "    totalPub = x\n",
    "    \n",
    "    # Create variables for the number of publications per journal type per role.\n",
    "    x = v[['Grant.Application.ID','Role','A.','A','B','C']].rename(columns={'A.':'Astar'}).\\\n",
    "        groupby(['Grant.Application.ID','Role']).\\\n",
    "        agg({'Astar':'sum','A':'sum', 'B':'sum','C':'sum'}).reset_index()\n",
    "    pt = x.pivot(index='Grant.Application.ID', columns = 'Role', values = ['Astar','A','B','C']).fillna(0)\n",
    "    newColNames = [x[0]+'.'+shortNames[x[1]] for x in pt.columns]\n",
    "    pt.columns = newColNames\n",
    "    pt = pt.reset_index()\n",
    "    investPub = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "    \n",
    "    # Create variables for each RFCD code\n",
    "    x = v[['Grant.Application.ID','RFCD.Code']].\\\n",
    "        groupby(['Grant.Application.ID','RFCD.Code']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    pt = x.pivot(index='Grant.Application.ID', columns = 'RFCD.Code',values = 'num').reset_index().drop(columns = ['RFCDNA']).fillna(0)\n",
    "    pt.columns.names=[None]\n",
    "    RFCDcount = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))\n",
    "\n",
    "    # Create variables for each SEO code\n",
    "    x = v[['Grant.Application.ID','SEO.Code']].\\\n",
    "        groupby(['Grant.Application.ID','SEO.Code']).\\\n",
    "        agg(num = ('Grant.Application.ID','count')).reset_index()\n",
    "    pt = x.pivot(index='Grant.Application.ID', columns = 'SEO.Code',values = 'num').reset_index().fillna(0).drop(columns = ['SEONA'])\n",
    "    pt.columns.names=[None]\n",
    "    SEOcount = noZV(allID.merge(pt, on = ['Grant.Application.ID'], how = 'left'))    \n",
    "    \n",
    "    # Create the grantData\n",
    "    x = raw[[\"Sponsor.Code\", \"Contract.Value.Band...see.note.A\", \"Grant.Category.Code\"]]\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    startTime = raw['Start.date'].apply(lambda x : datetime.strptime(x,'%d/%m/%y'))\n",
    "    startYear = startTime.apply(lambda x: x.year)\n",
    "\n",
    "    mthabbre=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    wdayabbre = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "    x['Month'] = startTime.apply(lambda x: mthabbre[x.month-1])\n",
    "    x['Day'] = startTime.apply(lambda x: x.day)\n",
    "    x['Weekday']=startTime.apply(lambda x: wdayabbre[x.dayofweek])\n",
    "\n",
    "    y = enc.fit_transform(np.array(x[['Sponsor.Code', \"Contract.Value.Band...see.note.A\", \"Grant.Category.Code\",'Month','Weekday']]))\n",
    "    y = pd.DataFrame(data = y.toarray(),columns = enc.get_feature_names_out())\n",
    "    y = y.rename(columns = dict(zip(list(y.columns), [x[3:] for x in y.columns])))\n",
    "    y['Day'] = x['Day']\n",
    "    y['Grant.Application.ID'] = raw['Grant.Application.ID']\n",
    "    y['Class'] = raw['Grant.Status'].map({0:'unsuccessful', 1:'successful'})\n",
    "    y['is2008'] = startYear == 2008\n",
    "    y.columns = [a.strip() for a in y.columns]\n",
    "    grantData = noZV(y)\n",
    "    \n",
    "    # Merge all the predictors together, remove zero variance columns and merge in the outcome data\n",
    "    summarized = investCount\n",
    "    for x in [investDOB, investCountry, investLang, investPhD, investGrants, \\\n",
    "        investDept, investFaculty, investDuration, investPub, totalPub, people, RFCDcount, SEOcount, grantData]:\n",
    "        summarized = summarized.merge(x, on = ['Grant.Application.ID'], how = 'left')\n",
    "    \n",
    "    return investCount, investDOB, investCountry, investLang, investPhD, investGrants, \\\n",
    "        investDept, investFaculty, investDuration, investPub, totalPub, people, RFCDcount, SEOcount, grantData, summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff5364d-fd72-43a9-8c28-f664738f3fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkVerticalData():\n",
    "    vertical_filename='vertical.csv'\n",
    "    vertical_path = os.path.join(unimelbdatafolder, vertical_filename)\n",
    "\n",
    "    v0 = pd.read_csv(vertical_path)\n",
    "    v0['RFCD.Code'] = v0['RFCD.Code'].fillna('RFCDNA')\n",
    "    v0['SEO.Code'] = v0['SEO.Code'].fillna('SEONA')\n",
    "    v0['Dept.No.'] = v0['Dept.No.'].fillna('DeptNA')\n",
    "    v0['Faculty.No.'] = v0['Faculty.No.'].fillna('FacultyNA')\n",
    "\n",
    "    v0s = v0.sort_values(['Grant.Application.ID','RFCD.Code']).reset_index(drop=True)\n",
    "    vs = v.sort_values(['Grant.Application.ID','RFCD.Code']).reset_index(drop=True)\n",
    "    return v0s.equals(vs)\n",
    "\n",
    "def checkSummaryData():\n",
    "    s = getSummaryData(v)[15]\n",
    "    s.columns = [x.lower() for x in s.columns]\n",
    "    s =s.drop(columns = ['grant.application.id'])\n",
    "\n",
    "    summary_filename='summarized.csv'\n",
    "    summary_path = os.path.join(unimelbdatafolder, summary_filename)\n",
    "    s0 = pd.read_csv(summary_path)\n",
    "    s0.columns = [x.lower() for x in s0.columns]\n",
    "\n",
    "    cm = s[list(s0.columns)]==(s0)\n",
    "    diffcol = []\n",
    "    for x in s.columns:\n",
    "        if (len(cm[x].value_counts())!=1):\n",
    "            diffcol.append(x)\n",
    "\n",
    "    # Check columns with PhD information: differ by NaN values\n",
    "    p = getSummaryData(v)[4]\n",
    "    p.columns = [x.lower() for x in p.columns]\n",
    "\n",
    "    PHD_filename='investPhD.csv'\n",
    "    PHD_path = os.path.join(unimelbdatafolder, PHD_filename)\n",
    "\n",
    "    p0 = pd.read_csv(PHD_path)\n",
    "    p0.columns = [x.lower() for x in p0.columns]\n",
    "    p0 = p0[list(p.columns)]\n",
    "\n",
    "    p = p.fillna('Missing')\n",
    "    p0 = p0.fillna('Missing')\n",
    "\n",
    "    # Check country columns: fill nan by 0 in getSummaryData\n",
    "    c = getSummaryData(v)[2]\n",
    "    c.columns = [x.lower() for x in c.columns]\n",
    "    for x in c.columns:\n",
    "        c[x]=c[x].fillna(0).astype('int64')\n",
    "\n",
    "    Country_filename='investCountry.csv'\n",
    "    Country_path = os.path.join(unimelbdatafolder, Country_filename)\n",
    "\n",
    "    c0 = pd.read_csv(Country_path)\n",
    "    c0.columns = [x.lower() for x in c0.columns]\n",
    "    c0 = c0[list(c.columns)]\n",
    "\n",
    "    # Check DOB columns: fill nan by 0 in getSummaryData\n",
    "    b = getSummaryData(v)[1]\n",
    "    b.columns = [x.lower() for x in b.columns]\n",
    "    for x in b.columns:\n",
    "        b[x]=b[x].fillna(0).astype('int64')\n",
    "\n",
    "    DOB_filename='investDOB.csv'\n",
    "    DOB_path = os.path.join(unimelbdatafolder, DOB_filename)\n",
    "\n",
    "    b0 = pd.read_csv(DOB_path)\n",
    "    b0.columns = [x.lower() for x in b0.columns]\n",
    "    b0 = b0[list(b.columns)]\n",
    "\n",
    "    return p0.equals(p), c0.equals(c), b0.equals(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571291b8-6ee6-4c19-a61f-9b73c9a7ed76",
   "metadata": {},
   "source": [
    "#### Read csv file and get summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d2b1dd-4058-4627-a491-bead6945bb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8708 entries, 0 to 8707\n",
      "Columns: 251 entries, Grant.Application.ID to C.15\n",
      "dtypes: float64(179), int64(2), object(70)\n",
      "memory usage: 16.7+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/7_5tv8fd44j9lk4v29938klw0000gn/T/ipykernel_3511/1944239768.py:1: DtypeWarning: Columns (90,105,119,120,123,124,132,134,135,138,139,147,149,150,153,154,162,164,165,168,169,177,179,183,184,192,194,198,199,207,209,213,214,224,237,239,244) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw = pd.read_csv(trainfile_path)\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv(trainfile_path)\n",
    "raw = raw.drop(columns = ['Unnamed: 251'])\n",
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53456b0b-f535-448e-92ba-39ceaeada36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "namesPre = []\n",
    "int1to15 = [str(x) for x in range(1,16)]\n",
    "for x in raw.columns:\n",
    "    if x[x.rfind(\".\")+1:] in int1to15:\n",
    "        if x[:x.rfind(\".\")] not in namesPre:\n",
    "            namesPre.append(x[:x.rfind(\".\")])\n",
    "bYears = np.unique(raw[[x for x in raw.columns if 'Year.of.Birth' in x]].stack().values).astype('int')\n",
    "dpmt = np.unique(raw[[x for x in raw.columns if 'Dept.No' in x]].stack().values).astype('int')\n",
    "raw = cleanRawData(raw)\n",
    "vertical = getVerticalData(raw,namesPre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ef5bc3-e7e8-4962-8404-da527f44c12c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertical = getVerticalData(raw,namesPre)\n",
    "vertical =cleanVerticalData(vertical)\n",
    "v = vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f2e784-ac80-44c0-a633-39cceb813980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shortNames = {\"EXT_CHIEF_INVESTIGATOR\":\"ECI\", \"STUD_CHIEF_INVESTIGATOR\":\"SCI\", \"CHIEF_INVESTIGATOR\":\"CI\",\\\n",
    "             \"DELEGATED_RESEARCHER\":\"DR\", \"EXTERNAL_ADVISOR\":\"EA\", \"HONVISIT\":\"HV\",\\\n",
    "             \"PRINCIPAL_SUPERVISOR\":\"PS\", \"STUDRES\":\"SR\", \"Unk\":\"UNK\", \"\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00758fd-fe99-4c4a-abc9-8e31b1d541b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
